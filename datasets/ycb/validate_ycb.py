### Description
#
# How to run
# python3 validate_ycb.py <data root folder> <data name without suffix> <model path (support *.xyz and *.obj>
# ex: want to validate "./ycb_subset/data/0000/000003-color.png" data
# python3 validate_ycb.py ./ycb_subset/data/0000 000003 ./ycb_subset/models/009_gelatin_box/points.xyz
#
# this script will show an interactive plot showing three objects 
# (model at origin, points cloud projected from depth image, and model applied ground truth translation and rotation)
# You should only see two points clouds becasue points cloud projected from depth image and model applied ground truth translation and rotation
# should completely overlap with each other
#
# You can further visualize it by putting three *.ply files generated by this script into MeshLab



import os
import sys
from PIL import Image
import numpy as np
import numpy.ma as ma
import scipy.io as scio
from pathlib import Path

import open3d as o3d

idx = 0 # ycb might have multiple in one data. Here we only validate the first object each data

cam_cx = 312.9869
cam_cy = 241.3109
cam_fx = 1066.778
cam_fy = 1067.487

def load_model_points_from_xyz(model_path):

    cld = []
    with model_path.open() as input_file:
        while 1:
            input_line = input_file.readline()
            if not input_line:
                break
            input_line = input_line[:-1].split(' ')
            cld.append([float(input_line[0]), float(input_line[1]), float(input_line[2])])
        cld = np.array(cld)
    return cld

if __name__ == '__main__':
    root = Path(sys.argv[1])
    data_index = sys.argv[2]
    model_path = Path(sys.argv[3])

    depth = np.array(Image.open(root / '{}-depth.png'.format(data_index)))
    label = np.array(Image.open(root / '{}-label.png'.format(data_index)))
    meta = scio.loadmat(root / '{}-meta.mat'.format(data_index))
    obj = meta['cls_indexes'].flatten().astype(np.int32)

    img_width = label.shape[0]
    img_length = label.shape[1]

    xmap =np.array([[j for i in range(img_length)] for j in range(img_width)])
    ymap = np.array([[i for i in range(img_length)] for j in range(img_width)])


    ### calculate the projected model from depth image
    mask_depth = ma.getmaskarray(ma.masked_not_equal(depth, 0))
    mask_label = ma.getmaskarray(ma.masked_equal(label, obj[idx]))
    mask = mask_label * mask_depth

    choose = mask.flatten().nonzero()[0]
    depth_masked = depth.flatten()[choose][:, np.newaxis].astype(np.float32)
    xmap_masked = xmap.flatten()[choose][:, np.newaxis].astype(np.float32)
    ymap_masked = ymap.flatten()[choose][:, np.newaxis].astype(np.float32)

    cam_scale = meta['factor_depth'][0][0]
    pt2 = depth_masked / cam_scale
    pt0 = (ymap_masked - cam_cx) * pt2 / cam_fx
    pt1 = (xmap_masked - cam_cy) * pt2 / cam_fy
    points_projected_from_depteh_image = np.concatenate((pt0, pt1, pt2), axis=1)

    FOR = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0,0,0])
    pcld_projected_from_depteh_image = o3d.geometry.PointCloud()
    pcld_projected_from_depteh_image.points = o3d.utility.Vector3dVector(points_projected_from_depteh_image)

    
    ### read the model at origin
    if "obj" in model_path.suffix:
        model_at_origin = o3d.io.read_triangle_mesh(str(model_path))
        model_at_origin = np.array(model_at_origin.vertices)
    else:
        model_at_origin = load_model_points_from_xyz(model_path)

    model_at_origin_pcld = o3d.geometry.PointCloud()
    model_at_origin_pcld.points = o3d.utility.Vector3dVector(model_at_origin)
        
    
    ### apply ground truth rotation and translation on model at origin
    target_r = meta['poses'][:, :, idx][:, 0:3]
    target_t = np.array([meta['poses'][:, :, idx][:, 3:4].flatten()])

    target = np.dot(model_at_origin, target_r.T)
    target = np.add(target, target_t)

    model_applied_gt_pose_pcld = o3d.geometry.PointCloud()
    model_applied_gt_pose_pcld.points = o3d.utility.Vector3dVector(target)


    ### generate visualization
    o3d.io.write_point_cloud("model_applied_gt_pose_pcld.ply", model_applied_gt_pose_pcld)
    o3d.io.write_point_cloud("pcld_projected_from_depteh_image.ply", pcld_projected_from_depteh_image)
    o3d.io.write_point_cloud("model_at_origin_pcld.ply", model_at_origin_pcld)

    o3d.visualization.draw_geometries([model_applied_gt_pose_pcld, model_at_origin_pcld, FOR, pcld_projected_from_depteh_image])





